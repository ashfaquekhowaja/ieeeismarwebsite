---
layout: 2025/page
title: Paper Reviewing Guidelines
---
*Last updated: 2025-03-26 2:48AM GMT*

This document guides those who participate in the ISMAR 2025 reviewing process and is directed towards those who perform full reviews of papers (i.e., secondary review coordinator 2AC, committee members, and reviewers) and meta-reviews (primary review coordinator, or 1AC). 

This guideline covers recommendations and best practices. Therefore, please read carefully the guidelines below. Finally, to ensure the integrity of the review process, we ask that reviewers **refrain from uploading papers to any AI system** (e.g., Claude AI, Wordtune, etc.) for analysis, support, or guidance during the review period, **nor write their review using these systems.**

## Cycle 1: Initial Review

- We consider a paper of sufficient quality if it provides obvious and strong contributions to the field, either in theory, methods, engineering, design, framework/taxonomy, and/or evaluation approaches. 
- Consider the value of the contribution and merits of the paper to the ISMAR community. The paper may be an edge case. But, if it discusses a topic that is currently unknown to the community or is extremely relevant at the time of submission, then it should be considered and reviewed accordingly. 
- The two-cycle review process of ISMAR 2025 will ask you to first provide a 4-point initial assessment on the likelihood of successful revision. Your ratings will determine the group of submissions selected for a revision and resubmission. 
- In general, as you perform your review, we ask that you reflect on the overall merit of the work and read papers with care and sympathy. Avoid seeking hidden flaws. Many hours of work — in some cases, years of work — have gone into the research and writing of this paper. Try to avoid last-minute reviews.
- Your score should reflect on the paper as a conference paper publication, not a journal paper submission.


### Review Scores: 

The section explains the ISMAR 4-point ranking used in the initial round of reviews and explains when we think one should select a particular score. We are aware that the decision can be subjective in many cases and that selecting between two is often a judgment call. We hope that this explanation removes some gray area for decision-making and helps to align reviewers on how to make borderline decisions for ratings. 

1.	**Highly Likely to Revise Successfully:** This paper has only minor issues. Revisions will be manageable and likely to succeed.
2.	**Moderately Likely to Revise Successfully:** While the paper is promising, there are notable issues requiring substantial revision. With careful and thoughtful revisions, the paper has a good chance of improving.
3.	**Uncertain:**  Major components of the research, such as theoretical grounding, methodology, or data interpretation, may need rethinking or substantial rewriting. Success is possible but uncertain. 
4.	**Unlikely to Revise Successfully:**  The paper has significant flaws making it unlikely that revisions will bring it to an acceptable standard. The likelihood of success after revisions is very low, and it may require a complete overhaul to address core issues.

## Cycle 2: Re-Review for Selected Submissions

-Based on the rating in Cycle 1, a selected set of manuscripts will be invited to revise and resubmit their paper. 
All reviewers will be asked to provide a short review of the revised version and the rebuttal document. Reviewers then score the revised paper on a 6-point ranking, and participate in a discussion to provide a final recommendation. 


### Review Scores: 6-point Ranking  

The section explains the ISMAR 6-point ranking and explains when we think one should select a particular score. We are aware that the decision can be subjective in many cases and that selecting between two is often a judgment call. We hope that this explanation removes some gray area for decision-making and helps to align reviewers on how to make borderline decisions for ratings.  

- Definitely accept (rating of 6): I would argue strongly for accepting this submission.
Select this option if the paper is acceptable as-is (except for minor edits), with a strong contribution and merits for the ISMAR community. 
- Probably accept  (rating of 5): I would argue for accepting this submission.
Select this option if the paper has a valid contribution and merits for the ISMAR community. Some additional explanations or minor corrections are required. 
- Weak accept  (rating of 4): The paper has weaknesses but the contributions outweigh the weaknesses. Select this option if the research is relevant, the topic is of value for the ISMAR community, and the attitude towards this contribution is overall positive despite the identified weaknesses.
- Weak reject (rating of 3): The paper has contributions but the weaknesses outweigh the contributions. Select this option if the research is relevant, the topic is of value for the ISMAR community, but the attitude is overall negative because of the identified weaknesses.
- Probably reject (rating of 2): I would argue for rejecting this submission.
Select this option if the research is relevant and the topic is of value for the ISMAR community, but the research has several severe weaknesses.
- Definitely reject (rating of 1): I would argue strongly for rejecting this submission. 
Select this option if the contribution is not understandable and the paper has no recognizable merits, or it is entirely unclear what information the ISMAR community gains from this submission. 

## Writing a Review

The following guidelines outline the content and key points of a high-quality review for ISMAR 2025. We believe that all paper reviews should be written with the same guidelines in mind. Please adhere to the guidelines and contact the program chairs or review coordinators for any questions. 
- A high-quality review should have about 1-page of well-considered commentary (at least 500 words), or more, if warranted. Short and/or content-free reviews are insufficient and frustrate the authors. 
- While we expect high-quality reviews, as ISMAR and TVCG will only accept high-quality papers that also receive high-quality reviews. The reviews are checked by the administration to ensure quality before acceptance is confirmed.
- The program committee and primary reviewers will be asked to evaluate the reviews for paper submissions based on the criteria of ISMAR. Those criteria are given here:
“When assessing the reviews, ask yourself, “Does the reviewer provide specific feedback in their ‘Public Comments’ (which are comments for the author) for a recommendation to be made?” We recommend reading the review reports to make sure they meet appropriate standards of quality, thoroughness, and professionalism. If a review lacks sufficient detail or is otherwise incomplete, please ask the reviewer for more information or invite a new reviewer, so that the recommendation and decision are substantiated by these comments. Further, It is unacceptable for a reviewer to require additional citations for the sole purpose of influencing bibliometric measures of either an individual or a periodical, as mentioned in the [IEEE PSPB Operations Manual (PDF)](https://www.ieee.org/documents/opsmanual.pdf) Section 8.2.2.A.4.”

- Thus reviewers must state specifically the reason(s) for the decision selected for the paper. Clearly describe on what grounds the paper should be accepted (or rejected).
- Reviewers should describe the contributions in the paper and why they are noteworthy or important to the community.
- They should explicitly and clearly discuss the weaknesses and limitations in a positive and constructive manner. Specifically, be positive and not insulting. 
- Reviewer comments should assess the work the authors did and whether their methods are appropriate to support their claims. They should avoid judging and explaining what the authors should have done.

Mind that your decisions affect the public appearance of ISMAR 2025. Therefore, the program chairs are very serious about ensuring the highest possible reviewing standards for ISMAR 2025. The coordinators and/or program chairs will ask you to improve your review if they think the reasons for your judgment are unclear.

We strongly recommend that you read the entire (short) article by Ken Hinckley, which we found to give a lot of constructive advice:
[Hinckley, K. (2016). So You’re a Program Committee Member Now: On Excellence in Reviews and Meta-Reviews and Championing Submitted Work That Has Merit].(https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Excellence-in-Reviews-MobileHCI-2015-Web-Site.pdf)

Here are some of the major elements from Hinckley’s paper, in some cases modified by adding insights from further advice by Steve Mann and Mark Bernstein, for quick reference:
- A high quality review should have a number of paragraphs (or even several pages of well-considered commentary if warranted).
- Short and/or content-free reviews are insufficient and will be caught by our reviewer’s review process.
- **Read papers with care and sympathy**. Many hours of work — in some cases, years of work — have gone into research and writing this paper. Try to avoid last-minute reviews.
- State specifically why the paper is “great”, “mediocre” or “bad”.
- Clearly describe on what grounds the paper should be accepted (or rejected).
- Describe the contributions in the paper and why they are noteworthy, or important.
- Reflect on the contributions or possible contributions of the work.
- Explicitly and clearly discuss the weaknesses and limitations in a positive and constructive manner. Specifically, don’t be insulting – be positive.
- Clearly and explicitly call out the strengths and utility of the work.
- **Your review should not be about what should have been done; rather it should be a critique of what the authors actually did.**
- Consider how the author’s arguments, results, and demonstrations fit into closely related work as well as the field as a whole.
- Do not reject a paper because of a few missed citations.
- In fact, do not reject a paper because of anything that can be easily fixed/addressed. Clearly state the requirements as all conditionally accepted papers will be shepherded towards an improved version that fulfills those requirements.
- A paper’s failure to justify or fully motivate certain decisions likely represent a correctable oversight, not an unequivocal sign of poorly conceived research.
- Avoid the fallacy of novelty. Specifically, do not simply reject papers because they replicated experiments.
- Reviewing scores: Around 2/3 of your rankings should be 1 or 6, around 1/3 should be 2 or 5, and you should rarely, rarely, rarely give a rating of 3 or 4.

From ISMAR’s perspective, we would like to add that in your role to maintain the high-quality of papers, we ask that you not categorically find hidden flaws and assassinate papers wherever possible but instead review papers for their merits.
When reviewing, keep in mind that almost every paper we review “could have done x, or y, or z”. Don’t fall into this trap! We cannot reject papers because authors did not perform their research the way we would have done it, or even how it is typically done. Instead, we must judge each paper on its own merit, and whether or not the body of work presented can stand on its own, as presented. Sure, every paper “could have done more”, but is the work that has been done of sufficient quality and impact?

Furthermore, **we should not reject papers because “this experiment has been done before”.**  This fallacy of novelty, ignores the long-standing tradition in science of replication.  New work that performs similar research and finds consistent (or even conflicting) results are of value to the community and to science in general, and should be considered on their own merits.
When evaluating papers that run human-subjects studies, it is important that the participant sample population is representative of the population for which the technology is being designed. For example, if the technology is being designed for a general population, then the participant population should include equal gender representation and a wide range of ages. All papers with human-subject studies must report at a minimum demographic information including age, gender, and every possible hint of social and diversity representation. If this is not the case, reviewers should not automatically reject the paper, but instead provide appropriate constructive critique and advice regarding general claims that do not use representative sample populations.

And finally, to quote Ken Hinckley: **“When in doubt, trust the literature to sort it out.”**

## Writing a Meta-Review 
The following guidelines outline the content of a good meta-reviews. The section is for review coordinators (1AC) and explains the content the chairs believe best supports a decision. 

- Describe the primary contribution of the paper.
- Summarize the most significant pros and cons of the paper. The most critical are often those the majority of reviewers highlight in their reviews. Abstain from reiterating every single aspect (we have the reviews for that). 
- Explain the decision and the pros and cons that support this decision. 
- In case of conditional acceptance, describe the conditions the authors have to meet before the paper can be accepted. 
- In case the paper is rejected, add suggestions for improvement. 
- Avoid adding discussion details or the score into the meta-review.

Mind that the authors will see the meta-review with the final decision. Be constructive and explain more rather than less, especially for cases when the authors receive an unfavorable decision. Very often, the research or paper was not ready at the time of submission. Invite the authors to re-submit next year if feasible.

## Frequently Asked Questions (FAQs)

- Should we reject papers that have been published on ArXiv?

No, you should not reject papers that have been published on ArXiv or a similar service, as authors may have done it as a way to get a timestamp for their work. However, if the ArXiv submission explicitly states that the submission is under review at ISMAR, was created within 30 days of the ISMAR submission deadline, or if the authors listed this prepublication on their individual or institutional webpages or generated publicity for it through other forms of media, then yes, it may constitute a violation of ISMAR policies. Please raise any related concerns in your review and/or contact the Program Chairs by email at: program2025@ieeeismar.net Please read the full "Double-Blind Process and Anonymity Policy" in the Author Guidelines.
 
- Should we reject papers that have been presented before in a different format (e.g., poster or demo)?

In some situations, a submission may build upon prior work. As part of the Author Guidelines, paper authors were instructed to be proactive about clarifying such cases by uploading additional documents to the submission system that are anonymous and will be considered during the review process. If you suspect any issues related to this point, please first contact the primary coordinator of this paper. If no clarification has been uploaded by the authors, please carefully assess how far the publications overlap. Note that ISMAR does not consider a prior non-archival 2-page poster/demo extended abstract a reason for rejection of a paper submitted on the same topic.

- Should we reject papers covering user studies that have no ethics review or institutional review board approval?

The authors will provide information whether they followed the ethical guidelines imposed by their affiliation and report if approval has been obtained or why no approval may have been necessary in the submission form. This will be considered during the review process. 
As such, the lack of a clear statement on ethics review and participant consent in the paper should be raised but not be grounds for rejection past the desk-reject stage. 

Thank you for your support and work to ensure the highest-quality ISMAR reviews.

## Document History

This document was updated and extended by the ISMAR 2025 Paper Chairs: Ulrich Eck, Gun Lee, Alexander Plopski, Missie Smith, Qi Sun, Markus Tatzgern, extended by the ISMAR 2024 Program Chairs:  Ulrich Eck, Misha Sra, Jeanine Stefanucci, Maki Sugimoto, Markus Tatzgern, Ian Williams after being extended by the ISMAR 2023 Conference Paper Chairs: Jens Grubert, Andrew Cunningham, Evan Peng, Gerd Bruder, Anne-Hélène Olivier, and Ian Williams. These guidelines were updated for the ISMAR 2022 conference papers review process: Henry Duh, Jens Grubert, Jianmin Zheng, Ian Williams, and Adam Jones. These guidelines are based on the work of the ISMAR 2019 PC Chairs: Shimin Hu, Denis Kalkofen, Joseph L. Gabbard, Jonathan Ventura, Jens Grubert, and Stefanie Zollmann.

<br>
---
*Do not hesitate to contact us for any further information: program2025@ieeeismar.net*
*ISMAR 2025 Paper Chairs*
*Ulrich Eck, Gun Lee, Alexander Plopski, Missie Smith, Qi Sun, Markus Tatzgern*
